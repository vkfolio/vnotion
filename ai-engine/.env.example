# VNotions AI Engine Environment Configuration
# Copy this file to .env and update with your actual values

# Server Configuration
AI_ENGINE_HOST=127.0.0.1
AI_ENGINE_PORT=8000
AI_ENGINE_DEBUG=false

# OpenAI Configuration (Optional)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Configuration (Optional)
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TIMEOUT=300

# Default Models
DEFAULT_TEXT_MODEL=llama2
DEFAULT_EMBEDDING_MODEL=all-MiniLM-L6-v2

# Performance Settings
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=300

# Storage Paths
MODELS_DIR=./models
CACHE_DIR=./cache

# Logging
LOG_LEVEL=INFO
LOG_FILE=

# Security (for production)
# API_KEY_REQUIRED=false
# RATE_LIMIT_REQUESTS_PER_MINUTE=60